[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "30DCC (2025)",
    "section": "",
    "text": "Overview\nThis is my second year participating in the 30-day chart challenge.\n\n\n\nFractionsSlopeCircularBig Or SmallRankingFlorence NightingaleOutliersHistogramDivergingMulti ModalStripesData GovClustersKinshipComplicatedNegativeBirdsEl PaisSmoothUrbanizationFossilsStarsLog ScaleWhoRiskMonochromeNoiseInclusionExtraterrestrialNational Geographic",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "01-fractions.html",
    "href": "01-fractions.html",
    "title": "\n1  Fractions\n",
    "section": "",
    "text": "1.1 Papercheck\nPapercheck is an R package I’m working on with Daniel Lakens and colleagues. The purpose is to help researchers assess best practices in methodology and reporting. It can also be used to make meta-scientific work scriptable and easier.",
    "crumbs": [
      "Comparisons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fractions</span>"
    ]
  },
  {
    "objectID": "01-fractions.html#papercheck",
    "href": "01-fractions.html#papercheck",
    "title": "\n1  Fractions\n",
    "section": "",
    "text": "1.1.1 PsychSci Open Badges\nThe package comes with a built-in dataset of 250 open-access papers from Psychological Science.\nYou can use the search_text() function to search any sentences that contain the word “badge”.\n\nbadges &lt;- psychsci |&gt;\n  search_text(\"badge\")\n\nCheck all the permutations of the badge statements.\n\ncount(badges, text, sort = TRUE)\n\n\n\n\n\nIt looks like the relevant statements all contain the word “received”.\n\nbadges &lt;- psychsci |&gt;\n  search_text(\"badge\") |&gt;\n  search_text(\"received\")\n\n\ncount(badges, text, sort = TRUE)\n\n\n\n\n\nUse grepl() to determine if these sentences contain the text “open data”, “open materials” and/or “preregistration”.\n\nbadges &lt;- badges |&gt;\n  mutate(data = grepl(\"open data\", text, ignore.case = TRUE),\n         materials = grepl(\"open materials\", text, ignore.case = TRUE),\n         prereg = grepl(\"preregistration\", text, ignore.case = TRUE),\n         ) |&gt;\n  select(id, data, materials, prereg)\n\n\n1.1.2 Paper Info\nNow you can use the info_table() function to get information about each paper’s submission and acceptance dates. Then join this to the badge data and set NA values to FALSE.\n\nall_papers &lt;- psychsci |&gt;\n  info_table(c(\"submission\")) |&gt;\n  separate(submission, c(\"received\", \"accepted\"), sep = \"; \") |&gt;\n  left_join(badges, by = \"id\") |&gt;\n  replace_na(replace = list(data = FALSE, \n                            materials = FALSE, \n                            prereg = FALSE))\n\nThe “submission” entry from grobid has a format like “Received 8/16/13; Revision accepted 12/22/13”, so it needs a little parsing (this is on my to-do list for automatically parsing when you load a grobid XML).\n\nm &lt;- gregexpr(\"\\\\d{1,2}/\\\\d{1,2}/\\\\d{2}\", all_papers$received)\nall_papers$year_received &lt;- regmatches(all_papers$received, m) |&gt; \n  lapply(mdy) |&gt;\n  sapply(\\(x) ifelse(length(x), year(x), NA))\n\nm &lt;- gregexpr(\"\\\\d{1,2}/\\\\d{1,2}/\\\\d{2}\", all_papers$accepted)\nall_papers$year_accepted&lt;- regmatches(all_papers$accepted, m) |&gt; \n  lapply(mdy) |&gt;\n  sapply(\\(x) ifelse(length(x), year(x), NA))\n\n\n1.1.3 Calculate Fractions of Open Practices\nCalculate the fraction of papers each year with open data, materials and preregistration.\n\nby_year &lt;- all_papers |&gt;\n  fill(year_received, year_accepted) |&gt;\n  pivot_longer(data:prereg) |&gt;\n  summarise(frac = mean(value), .by = c(year_received, name))",
    "crumbs": [
      "Comparisons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fractions</span>"
    ]
  },
  {
    "objectID": "01-fractions.html#plot",
    "href": "01-fractions.html#plot",
    "title": "\n1  Fractions\n",
    "section": "\n1.2 Plot",
    "text": "1.2 Plot\nPlot the data.\n\nfrac &lt;- c(0, 1/10, 1/5, 1/4, 1/3, 2/5, 1/2, 3/5,  2/3, 3/4, 4/5, 9/10, 1)\nlabel &lt;- c(\"0\", \"1/10\", \"1/5\", \"1/4\", \"1/3\", \"2/5\", \"1/2\", \"3/5\", \"2/3\", \"3/4\", \"4/5\", \"9/10\", \"1\")\n\nggplot(by_year, aes(x = year_received, y = frac, colour = name)) +\n  geom_point(size = 3) +\n  geom_line() +\n  scale_x_continuous(\"Year Received\", breaks = 2012:2024) +\n  scale_y_continuous(\"Fraction of Papers\", limits = c(0, 1),\n                     breaks = frac, labels = label) +\n  scale_colour_manual(\"Badge:\", values = c(\"firebrick\", \"darkgreen\", \"dodgerblue3\")) +\n  labs(title = \"Open Practice Badges\",\n       subtitle = \"250 Open Access Psychological Science Papers\",\n       \"debruine.github.io/30DCC-2025/01-fractions\") +\n  theme(legend.position = c(.2, .8), \n        plot.caption = element_text(color = \"dodgerblue\"))\n\n\n\n\n\n\nFigure 1.1: A chart showing the fraction of published papers received each year by Psychological Science, from 2012 to 2023, that have open data, open materials, or preregistration badges. The number is mostly increasing each year, with a sharp decrease in 2022.\n\n\n\n\nSomething weird was going on in 2022. Let’s figure it out later.",
    "crumbs": [
      "Comparisons",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fractions</span>"
    ]
  },
  {
    "objectID": "02-slope.html",
    "href": "02-slope.html",
    "title": "\n2  Slope\n",
    "section": "",
    "text": "2.1 Open Alex Info\nYou can get information about papers from Open Alex by DOI or from a papercheck paper object or list.\noa_info &lt;- openalex(psychsci[[1]])\nnames(oa_info)\n\n [1] \"id\"                             \"doi\"                           \n [3] \"title\"                          \"display_name\"                  \n [5] \"publication_year\"               \"publication_date\"              \n [7] \"ids\"                            \"language\"                      \n [9] \"primary_location\"               \"type\"                          \n[11] \"type_crossref\"                  \"indexed_in\"                    \n[13] \"open_access\"                    \"authorships\"                   \n[15] \"institution_assertions\"         \"countries_distinct_count\"      \n[17] \"institutions_distinct_count\"    \"corresponding_author_ids\"      \n[19] \"corresponding_institution_ids\"  \"apc_list\"                      \n[21] \"apc_paid\"                       \"fwci\"                          \n[23] \"has_fulltext\"                   \"fulltext_origin\"               \n[25] \"cited_by_count\"                 \"citation_normalized_percentile\"\n[27] \"cited_by_percentile_year\"       \"biblio\"                        \n[29] \"is_retracted\"                   \"is_paratext\"                   \n[31] \"primary_topic\"                  \"topics\"                        \n[33] \"keywords\"                       \"concepts\"                      \n[35] \"mesh\"                           \"locations_count\"               \n[37] \"locations\"                      \"best_oa_location\"              \n[39] \"sustainable_development_goals\"  \"grants\"                        \n[41] \"datasets\"                       \"versions\"                      \n[43] \"referenced_works_count\"         \"referenced_works\"              \n[45] \"related_works\"                  \"abstract_inverted_index\"       \n[47] \"abstract_inverted_index_v3\"     \"cited_by_api_url\"              \n[49] \"counts_by_year\"                 \"updated_date\"                  \n[51] \"created_date\"\nSadly, grobid doesn’t always parse the DOIs in papers correctly. For example, the 11th paper in the psychsci set has a DOI of “10.1177/0956797615603702pss.”, so will produce a warning and no data.\noa_info &lt;- openalex(psychsci[10:11])\n\nWarning: 10.1177/0956797615603702pss. not found in OpenAlex\n\noa_info[[2]]\n\n$error\n[1] \"10.1177/0956797615603702pss.\"\nWe can get a list of the DOIs of the psychsci set with the info_table() function and then fix them.\ndoi_table &lt;- info_table(psychsci, \"doi\")\n\ndoi_table |&gt; filter(grepl(\"[a-z]\", doi, ignore.case = TRUE))\n\n\n\n\n\nid\n\n\ndoi\n\n\n\n\n\n0956797615603702\n\n\n10.1177/0956797615603702pss.\n\n\n\n\n0956797615620784\n\n\n10.1177/0956797615620784pss.\n\n\n\n\n0956797616634665\n\n\n10.1177/0956797616634665pss.\n\n\n\n\n0956797616667447\n\n\n10.1177/0956797616667447pss.\n\n\n\n\n0956797616671327\n\n\n10.1177/0956797616671327pss.sagepub\n\n\n\n\n0956797616671712\n\n\n10.1177/0956797616671712journals.sagepub.\nPsychological Science DOIs should be entirely numeric, so we can just remove non-numeric characters after the / with a little regex.\ndois &lt;- sub(\"[a-z\\\\.]+$\", \"\", doi_table$doi)\nNow we can get all of the OpenAlex data from these papers. This will take a few minutes for 250 papers, and I don’t want to have to do this every time I render this book, so I’ll save the results as an Rds object, set this code chunk to not evaluate, and load it from the RDS in the future.\n```{r}\n#| eval: false\noa_info &lt;- openalex(dois)\nsaveRDS(oa_info, \"data/oa_info.Rds\")\n```\noa_info &lt;- readRDS(\"data/oa_info.Rds\")",
    "crumbs": [
      "Comparisons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Slope</span>"
    ]
  },
  {
    "objectID": "02-slope.html#tabular-data",
    "href": "02-slope.html#tabular-data",
    "title": "\n2  Slope\n",
    "section": "\n2.2 Tabular Data",
    "text": "2.2 Tabular Data\nNow we need to convert the data from OpenAlex to a table. We’re going to extract some information about dates of publication and citations.\n\n\ncited_by: The number of citations to this work.\n\nfwci: The Field-weighted Citation Impact (FWCI), calculated for a work as the ratio of citations received / citations expected in the year of publications and three following years\n\n\ninfo &lt;- oa_info[[1]]\ncites &lt;- map_df(oa_info, \\(info) {\n  list(\n    year = info$publication_year,\n    date = info$publication_date,\n    cited_by = info$cited_by_count,\n    fwci = info$fwci\n  )\n})\n\ncites",
    "crumbs": [
      "Comparisons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Slope</span>"
    ]
  },
  {
    "objectID": "02-slope.html#plots",
    "href": "02-slope.html#plots",
    "title": "\n2  Slope\n",
    "section": "\n2.3 Plots",
    "text": "2.3 Plots\n\n2.3.1 Citations by FWCI\nThe first, simplest plot is looking at the raw number of citations and the field-weighted citation impact.\n\nggplot(cites, aes(x = cited_by, y = fwci)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x)\n\n\n\n\n\n\n\nThe data might be better with a log10 scale, although this will remove values of 0, so let’s change any values of 0 to 0.1 and label this as 0 on the plot. First, though, we should check the range of fwci values to find a number we can safely convert zeroes to.\n\nmin_non0 &lt;- cites$fwci[cites$fwci &gt; 0] |&gt;\n  min(na.rm = TRUE)\n\ncites |&gt; filter(fwci &gt; 0) |&gt;\n  ggplot(aes(x = fwci)) +\n  geom_histogram(binwidth = 0.1, color = \"black\", fill = \"white\") +\n  geom_vline(xintercept = 0.1, colour = \"red\") +\n  scale_x_log10()\n\n\n\n\n\n\n\nIt looks like setting 0 to 0.1 will be safe for both citation count (where non-zero values logically can’t be lower than 1) and fwci (where non-zero values are all over 0.253).\n\ncites &lt;- rowwise(cites) |&gt;\n  mutate(cited_by = max(cited_by, 0.1),\n         fwci = max(fwci, 0.1))\n\nPlot this new data and change the 0.1 labels to 0.\n\nggplot(cites, aes(x = cited_by, y = fwci)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ x) +\n  scale_x_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000)) +\n  scale_y_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000))\n\n\n\n\n\n\n\n\n2.3.2 Interpretation\nSo now we can tell that number of citations and FWCI are positively related, but not perfectly, so what explains the disrepancy? We can look at the year of publication to see if there is a consistent relationship with time since publication.\n\nggplot(cites, aes(x = cited_by, y = fwci, colour = year)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ x, colour = \"black\") +\n  scale_x_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000)) +\n  scale_y_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000)) +\n  scale_color_viridis_c()\n\n\n\n\n\n\n\nIt looks like the more recent papers tend to be above the line, and older papers below the line. But I don’t like showing year as a continuous variable. Let’s convert it to a factor and set the colours using the rainbow() (I like to set v = 0.75 for a darker aesthetic, and only use the values 0-0.8 of the hue range so the start and end values aren’t confusable).\n\n# set colours for each level of the year factor\nrb_colours &lt;- cites$year |&gt;\n  unique() |&gt;\n  length() |&gt;\n  rainbow(v = 0.75, end = 0.8, rev = TRUE)\n\nggplot(cites, aes(x = cited_by, y = fwci, colour = factor(year))) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ x, colour = \"black\") +\n  scale_x_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000)) +\n  scale_y_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000)) +\n  scale_color_manual(values = rb_colours)\n\n\n\n\n\n\n\n\n2.3.3 Tidy Up\nClean up the labels with labs().\n\nggplot(cites, aes(x = cited_by, y = fwci, colour = factor(year))) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", formula = y ~ x, colour = \"black\") +\n  scale_x_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000)) +\n  scale_y_log10(breaks = c(0.1, 1, 10, 100, 1000),\n                labels = c(0, 1, 10, 100, 1000)) +\n  scale_color_manual(values = rb_colours) +\n  labs(title = \"The Relationship between Citations and FWCI\",\n       subtitle = \"235 Open Access Psychological Science Papers\",\n       x = \"Citation Count\",\n       y = \"Field Weighted Citation Impact\",\n       colour = \"Publication Year\",\n       caption = \"debruine.github.io/30DCC-2025/02-slope\") +\n  theme(legend.position = c(0.15, 0.75), \n        plot.caption = element_text(color = \"dodgerblue\"))\n\n\n\n\n\n\nFigure 2.1: A chart showing the relationship between citation count (plotted on the x-axis) and field-weighted citation impact (FWCI; plotted on the y-axis). The relation is strongly positive and linear, with some variation. The papers are represented by points with the colour by year of publication (2014-2024), showing that the papers above the regression line tend to be more recent, and those below the line tend to be older.",
    "crumbs": [
      "Comparisons",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Slope</span>"
    ]
  },
  {
    "objectID": "03-circular.html",
    "href": "03-circular.html",
    "title": "\n3  Circular\n",
    "section": "",
    "text": "library(papercheck)\nlibrary(tidyverse)\ntheme_set(theme_minimal(base_size = 15))\n\n\nbadges &lt;- read_csv(\"data/psychsci-badges.csv\") |&gt;\n  mutate(open = data | materials | prereg)\n\n\nggplot(badges, aes(x = year(date), \n                 y = cited_by, \n                 color = open)) +\n  geom_point(alpha = 0.2) +\n  scale_y_log10() +\n  coord_polar()",
    "crumbs": [
      "Comparisons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Circular</span>"
    ]
  }
]